{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0593ca9",
   "metadata": {
    "id": "b0593ca9"
   },
   "source": [
    "# Описание проекта\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "Построим модель со значением метрики качества F1 не меньше 0.75. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37092277",
   "metadata": {
    "id": "37092277"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42871e34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42871e34",
    "outputId": "ec365c4c-53d9-485a-f533-78d7bbcaea5a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "679c574f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "679c574f",
    "outputId": "a5fa749b-4d2a-4e00-9f3b-06345c398cfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "_sopL87ZCXdP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sopL87ZCXdP",
    "outputId": "bf54f7ce-b0a2-4aed-e697-a27e7e15ab13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac482c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "fac482c5",
    "outputId": "f781db8c-0aeb-452a-93b3-8fcdd1cab400"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv', index_col = [0])\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', index_col = [0])\n",
    "    \n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7909475e",
   "metadata": {
    "id": "7909475e"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d18aef",
   "metadata": {
    "id": "a2d18aef"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53700d19",
   "metadata": {
    "id": "53700d19"
   },
   "outputs": [],
   "source": [
    "def tokenizer (text):\n",
    "    words = word_tokenize(text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99c187b9",
   "metadata": {
    "id": "99c187b9"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(lambda x: tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c448146a",
   "metadata": {
    "id": "c448146a"
   },
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    lemma_words = [WordNetLemmatizer().lemmatize(i) for i in text]\n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e703f03c",
   "metadata": {
    "id": "e703f03c"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(lambda x:lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa395d3",
   "metadata": {
    "id": "6fa395d3"
   },
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    \n",
    "    clear_text = \" \".join(text)#.split())\n",
    "    return clear_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f25924cb",
   "metadata": {
    "id": "f25924cb"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(lambda x:clear_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73249b0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "73249b0b",
    "outputId": "4f9a9bf3-2a53-4a12-fe22-ce623b38d875"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he match this background colour i am see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can not make any real suggestion on imp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d aww he match this background colour i am see...      0\n",
       "2  hey man i am really not trying to edit war it ...      0\n",
       "3  more i can not make any real suggestion on imp...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f62907dc",
   "metadata": {
    "id": "f62907dc"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data,\n",
    "                               test_size = 0.2,\n",
    "                               random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9c2c862",
   "metadata": {
    "id": "c9c2c862"
   },
   "outputs": [],
   "source": [
    "corpus_train = train['text']\n",
    "corpus_test = test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e916da2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e916da2e",
    "outputId": "1da93046-23de-4b43-acae-139f0e08c47d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97494     bushranger you are a grass with no sense of hu...\n",
       "4383      need administrative help i have been blocked i...\n",
       "103777    i would also like to point out that he ha used...\n",
       "38619       you cant block me you fucking retard brb nigger\n",
       "128443    i believe that the frequency of the wave need ...\n",
       "                                ...                        \n",
       "110090    hahaha i dont live in a lie like you and dont ...\n",
       "85493                                 march 2006 march 2006\n",
       "133387    agreed we really should try to stick to the su...\n",
       "130469    umm killer do you not like that he copied your...\n",
       "77361      bradford city i am removing unreferanced content\n",
       "Name: text, Length: 127433, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c68a376",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c68a376",
    "outputId": "90e8e300-518b-4a62-b1ba-7974f3b2eac9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f86e814f",
   "metadata": {
    "id": "f86e814f"
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=list(stopwords), lowercase = False)\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus_train)\n",
    "tf_idf_test = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17f221e8",
   "metadata": {
    "id": "17f221e8"
   },
   "outputs": [],
   "source": [
    "target_train = train['toxic']\n",
    "target_test = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110d85d",
   "metadata": {
    "id": "d110d85d"
   },
   "source": [
    "Первая модель - логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1115282b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "id": "1115282b",
    "outputId": "dfe12320-0f6d-42b1-e9ed-3da977480c88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words=['had',\n",
       "                                                                    'same',\n",
       "                                                                    'themselves',\n",
       "                                                                    \"that'll\",\n",
       "                                                                    'being',\n",
       "                                                                    'were',\n",
       "                                                                    'yourself',\n",
       "                                                                    \"hadn't\",\n",
       "                                                                    'do',\n",
       "                                                                    \"mightn't\",\n",
       "                                                                    'this',\n",
       "                                                                    'ours',\n",
       "                                                                    'so',\n",
       "                                                                    \"didn't\",\n",
       "                                                                    'shan',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'against',\n",
       "                                                                    'while',\n",
       "                                                                    'out',\n",
       "                                                                    'and',\n",
       "                                                                    'few', 'o',\n",
       "                                                                    'of', 'a',\n",
       "                                                                    'just',\n",
       "                                                                    'during',\n",
       "                                                                    'isn',\n",
       "                                                                    'both',\n",
       "                                                                    'wasn', 'i', ...])),\n",
       "                                       ('logreg',\n",
       "                                        LogisticRegression(class_weight='balanced',\n",
       "                                                           random_state=12345,\n",
       "                                                           solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logreg__C': [1, 2, 6],\n",
       "                         'tfidf__max_df': (0.25, 0.5, 0.75),\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(stopwords))),\n",
    "    ('logreg', LogisticRegression(class_weight='balanced',\n",
    "                                    solver = 'liblinear',\n",
    "                                  random_state=12345)),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'logreg__C': [1,2,6]\n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, scoring='f1', verbose=0)\n",
    "grid_search_tune.fit(corpus_train, target_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fa54cfb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fa54cfb",
    "outputId": "cd82180b-ce46-4260-eb41-664aef7f5f32",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение  {'logreg__C': 6, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 2)} F1: 0.7711527136199212\n"
     ]
    }
   ],
   "source": [
    "print('Лучшее значение ', grid_search_tune.best_params_, 'F1:', grid_search_tune.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128a53e",
   "metadata": {
    "id": "1128a53e"
   },
   "source": [
    "Вторая модель - решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28b4ebee",
   "metadata": {
    "id": "28b4ebee"
   },
   "outputs": [],
   "source": [
    "parameters_tr = {'max_depth': range(1, 101, 10)}\n",
    "\n",
    "grid_tr = GridSearchCV(DecisionTreeClassifier(random_state=12345),\n",
    "                       cv = 2,\n",
    "                       param_grid = parameters_tr,\n",
    "                       n_jobs = -1,\n",
    "                       verbose = False,\n",
    "                       scoring = 'f1').fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4d0169b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4d0169b",
    "outputId": "fae47d4e-1981-47f5-8325-dc2568c233c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение  {'max_depth': 91} F1: 0.7118024475314888\n"
     ]
    }
   ],
   "source": [
    "print('Лучшее значение ', grid_tr.best_params_, 'F1:', grid_tr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VRVFeFqTLgLu",
   "metadata": {
    "id": "VRVFeFqTLgLu"
   },
   "source": [
    "Метрика 0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "GBDm6APX6sPD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBDm6APX6sPD",
    "outputId": "7bf22e57-5b96-4f57-da06-3dc04bef2ad1"
   },
   "outputs": [],
   "source": [
    "model_lgbm = LGBMClassifier()\n",
    "\n",
    "parameters_lgbm = {'n_estimators': (50, 201, 50),\n",
    "             'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "             'num_leaves': [10, 20, 30, 40, 50]}\n",
    "\n",
    "grid_lgbm = GridSearchCV(LGBMClassifier(),\n",
    "                         param_grid = parameters_lgbm,\n",
    "                         cv = 3,\n",
    "                         n_jobs = -1, \n",
    "                         scoring = 'f1').fit(tf_idf_train, target_train)\n",
    "\n",
    "\n",
    "print('Лучшие параметры', grid_lgbm.best_params_, 'F1:', grid_lgbm.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nDACLT5QO74u",
   "metadata": {
    "id": "nDACLT5QO74u"
   },
   "source": [
    "Метрика соответствует требованиям 0.764"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005053d8",
   "metadata": {},
   "source": [
    "Лучшая модель - линейная регрессия. Протестируем ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "K8m7O1qCPIn6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "K8m7O1qCPIn6",
    "outputId": "02395100-2806-48c8-8215-2012fb254325",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.7843254561770864\n"
     ]
    }
   ],
   "source": [
    "prediction = grid_search_tune.predict(corpus_test)\n",
    "print(\"F1_score:\", f1_score(target_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j3NemyBszu6s",
   "metadata": {
    "id": "j3NemyBszu6s"
   },
   "source": [
    "На тестовой выборке получена удовлетворительная метрика - 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nnYDvLCqz6_y",
   "metadata": {
    "id": "nnYDvLCqz6_y"
   },
   "source": [
    "Вывод:\n",
    "В ходе работы были обработаны комментарии - произведена токенизация, лемматизация, очистка. Далее они переведены в векторное представление. \n",
    "На данных обучены три модели. LightGBM поаказала наилучший результат."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
