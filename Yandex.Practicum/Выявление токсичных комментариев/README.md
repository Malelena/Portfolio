### Yandex.Practicum-Data-Science
# Определение токсичности комментариев (Обучение модели классификации комментариев)
## Описание проекта
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Требуется инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

### Описание данных
Данные находятся в файле toxic_comments.csv.
Столбец text в нём содержит текст комментария, а toxic — целевой признак.

### Используемые инструменты
`spacy` `pymystem3` `re` `sklearn` `pandas` `numpy` `matplotlib` `plotly` `math` `Python` `nltk` `tf-idf`

### Модели
`LogisticRegression` `RandomForestClassifier` `LightGBM` `DecisionTreeClassifier`

### Дополнительно
`TfidfVectorizer` `Lemmatizer` `GridSearchCV` `nltk` `tf-idf`

### Метрики
`f1_score`

### Вывод:

Проанализировав полученный датасет, привели все слова к нижнему регистру. Далее провели лемматизацию и почистили данные от различных символов, оставив только киррилические и пробелы.Увидели, что имеется значительный перевес в сторону нормальных комментариев. Далее разделили датасет на тренировочную и тестовую выборки и провели обучение моделей: логистическая регрессия, дерево решений и LGBMClassifier. Исходя из требований заказчика, мы должны были получить метрику F1 не менее 0.75. Лучший результат F1 = 0.76 показала модель LGBMClassifier, ее мы и выбрали для дальнейшей проверки на тестовой выборке. Результат улучшился, F1 = 0.77, таким образом, задача заказчика выполнена.

### Основные шаги и выводы:
* Анализ данных, подготовка
* Токенизация, очистка и лемматизация данных
* Сравнение нескольких моделей
* Достижение требуемой метрики заказчика
* Выводы
